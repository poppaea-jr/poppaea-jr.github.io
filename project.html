<!DOCTYPE html>
<html>

<!DOCTYPE html>
   <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Poppaea JR</title>
      
        <link rel="stylesheet" href="index.css">
      
        <style>
            @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap');
        </style>
      
      <!-- The next three lines allow the Vega ehitembed-->
      <script src="https://cdn.jsdelivr.net/npm/vega@5.17.0"></script>
      <script src="https://cdn.jsdelivr.net/npm/vega-lite@4.17.0"></script>
      <script src="https://cdn.jsdelivr.net/npm/vega-embed@6.12.2"></script>
      
      </head>
<body>
      <h1>Project Page</h1>

      <div class="wrap">
        <p> Head back to my homework portfolio <a class="textLink" href="index">here</a>.</p>
        
<h3>Do the Opinions of Reddit Users in r/Stocks Influence the Stock Market?</h3>
      
<p>To assess this question, I will perform a Sentiment Analysis on online posts, and compare how these vary over time to fluctuations in the S&P 500 close and volumes. I chose to collect my text data from Reddit because it makes its data particularly accessible through the Python Reddit API Wrapper.</p>

<div class="chart" id="chart21">
  <script>     var myChart21 = "charts/stocks_Polarity.json";
    vegaEmbed('#chart21', myChart21);
  </script>
</div>

<p>The above chart shows my first data pull for this project, the code for which can be found<a href="https://colab.research.google.com/drive/1A2LFGAsgmIev6hK05JuAApSLtGbLKhd5?usp=sharing"> in the colab notebook</a> or <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/stocks_fetch_and_pol.ipynb">on github</a>.
The challenge I faced here was that the timeframe of posts cannot be specified in a fetch using standard PRAW, and it will only pull around 900 posts per run. I therefore switched to Pushshift PRAW, however this API was limited to 100 posts per run. I circumvented this using a loop. An example of this notebook, including outputs for one day, can be found <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/Example_Notebook_PRAW_Loop.ipynb"> in my Github here</a>. After fetching the posts, the notebook uses TextBlob to assign a polarity value to each,  1 being entirely positive, and -1 being entirely negative. Due to the large amount of data being processed, I chose to run this loop for 1 month intervals, and then merge them <a href="https://colab.research.google.com/drive/1e7s4wn46n7bbQA3g5V2wuPUlwEoeInXr?usp=sharing">in Pandas,</a> see the code <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/merging_months.ipynb">in Github</a>.
Once I had collected data for the whole year, I collapsed it to daily values in Stata, see the <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/sentiment_data_collapse.do">Do file here</a>. I converted the dates to be Vega friendly in colab, and plotted the years time series below:</p>

<!-- Time series chart of sentiment polarity and sp -->

<div class="chart" id="chart22">
  <script>     var myChart22 = "charts/sentiment_time_series.json";
    vegaEmbed('#chart22', myChart22);
  </script>
</div>

<p>As my aim was to test whether the sentiment displayed in the forum over time influences changes in the market over time, I chose to test for Granger causality, that is whether the time-series of sentiment is useful in predicting the time-series of the market index. I tested with the null hypothesis that neither one was Granger causal of the other. In order to perform this test, both of my time series needed to be stationary.</p>

<p>Predictably, the series for S&P 500 Index Values was not stationary, and required first-differencing: see the <a href="https://colab.research.google.com/drive/1361n5kxDiiUatZiXa6N78e4GwuYZovzq?usp=sharing"> Colab notebook</a>, or view the code <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/yfin_stationarity.ipynb">on Github</a>.</p>

<div class="chart" id="chart31">
  <script>     var myChart31 = "charts/stationary_sp.json";
    vegaEmbed('#chart31', myChart31);
  </script>
</div>

<p>My time series for sentiment already appeared stationary according to a Dickey Fuller test, <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/sentiment_stationarity.ipynb">see the code</a>.</p>

<p>Now both series had a p-value less than 0.000 in their Dickey Fuller tests, indicating that the probability of this data occuring despite being non-stationary would be below 0.05%. I therefore interpreted this as them being stationary, and proceeded to the Granger test.</p>

<p>An extended version of my S&P fetch, which indludes this Granger test, can be found<a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/Granger_test.ipynb"> on my Github</a>. The smallest final p-value in the final Granger causation matrix was 0.2723, too large to reject the null hypothesis and therefore concluding that sentiment in r/stocks does not cause changes in the S&P 500 closing price.</p>

<div class="chart" id="chart32">
  <script>     var myChart32 = "charts/close_reg.json";
    vegaEmbed('#chart32', myChart32);
  </script>
</div>

<p>This result is unsurprising considering that the regression of the raw values yeilds an R-squared statistic of 0.</p>

<p>Secondly, repeating the analysis for stock volume rather than stock closing price found a Granger coefficient of 0.0023, a suficiently small p-value to reject the null hypothesis of no Granger causality at the 5% significance level, indicating that sentiment in the subreddit is Granger-causal of changes in the volume of trades of the S&P 500, <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/Granger_test_for_volume.ipynb">see the code in Github</a>.</p>

<div class="chart" id="chart33">
  <script>     var myChart33 = "charts/vol_reg.json";
    vegaEmbed('#chart33', myChart33);
  </script>
</div>

<p>This example using the r/Stocks subreddit indicates more broadly that text data is incredibly valuble. Already, there are automated traders which incorperate opinion dynamics into their decision making. My first steps to continue this work will be to extend the breadth of my text data to current events and other media such as Twitter.</p>






<h3>Appendix:</h3>

<p>Data containing polarity scores for every post prior to daily averaging is available <a href="https://github.com/poppaea-jr/poppaea-jr.github.io/blob/main/sentiment_time_series.csv">on my github</a></p>


<h3>References:</h3>
<p>PRAW: <a href="https://praw.readthedocs.io/en/stable/">read the docs</a></p>
<p>Pushift PRAW: <a href="https://github.com/pushshift/api">read the docs</a></p>
<p><a href="https://www.analyticsvidhya.com/"></a>Analytics Vidyha</p>
<p>TextBlob: <a href="https://textblob.readthedocs.io/en/dev/">read the docs</a></p>
<p>David Little at Arizona State University: <a href="https://github.com/UnitForDataScience/Reddit_Sentiment">Reddit Sentiment</a></p>


</body>
</html>
