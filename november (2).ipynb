{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qyx_qhTkET4Z"
   },
   "outputs": [],
   "source": [
    "# Using a loop and the Pushift PRAW API to gather posts from r/stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGbrEBsYCt3x",
    "outputId": "11cccbef-1e4a-44db-9606-baa5989f1f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\poppa\\anaconda3\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from praw) (1.2.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\poppa\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HAZSnl0ECmZ6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authentication information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvR0m31OCyuH",
    "outputId": "3689577c-6e14-460a-f6f2-faad4e03373d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/api/v1/authorize?client_id=Jef0auDOdnMZ9vD6zlcWRg&duration=permanent&redirect_uri=http%3A%2F%2Flocalhost%3A8080&response_type=code&scope=identity&state=...\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"Jef0auDOdnMZ9vD6zlcWRg\",\n",
    "    client_secret=\"XqXCuNc590taBMgauwFmMBpDqvZp0A\",\n",
    "    user_agent=\"poppaearedditapilink\",\n",
    "    redirect_uri=\"http://localhost:8080\",\n",
    ")\n",
    "print(reddit.auth.url([\"identity\"], \"...\", \"permanent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1GoTiv_LDwRd"
   },
   "outputs": [],
   "source": [
    "def submissions_pushshift_praw(subreddit, start=None, end=None, limit=10000, extra_query=\"\"):\n",
    "\n",
    "    # creating an array to contain submissions\n",
    "    posts = [] \n",
    "    \n",
    "\n",
    "\n",
    "    # preparing api link with {} for inputs specified later\n",
    "    api = ('https://api.pushshift.io/reddit/submission/search/?subreddit={}&after={}&before={}&sort_type=created_utc&sort=asc&limit={}&q={}')\n",
    "    api = api.format(subreddit, start, end, limit, extra_query)\n",
    "\n",
    "    # Using the api to fetch data in JSON form\n",
    "    data = requests.get(api)\n",
    "    json_data = data.json()['data']\n",
    "\n",
    "    # Using a for loop to iterate over each submission, convert them to a praw_submission object, and append them to posts\n",
    "    for submission in json_data:\n",
    "        # Take the ID, fetch the PRAW submission object, and append to our list\n",
    "        praw_submission = reddit.submission(id=submission['id'])\n",
    "        posts.append(praw_submission)\n",
    "\n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZSyRB_1aDfDR"
   },
   "outputs": [],
   "source": [
    "start_date = 1635724800 # 01/09/11 00:00:00\n",
    "end_date = 1638316800  # 01/10/11 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hZlT8UWQECWa"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVr3RymHEEG3",
    "outputId": "9d5028c5-8b29-4025-a8ed-c18b1f04968f"
   },
   "outputs": [],
   "source": [
    "# checking that the start date is infact before the end date, as a requirement for continuing to run the body of the loop\n",
    "while start_date < end_date:\n",
    "    # setting input values for our earlier url\n",
    "    S = submissions_pushshift_praw(subreddit='stocks', start=start_date, end=end_date)\n",
    "    # using a for loop over each post:\n",
    "    for post in S:\n",
    "        # stopping the loop from fetching deleted or removed posts\n",
    "        try:\n",
    "            if post.selftext != '[removed]' and post.selftext != '[deleted]':\n",
    "\n",
    "\n",
    "                    df = df.append(\n",
    "                        {'title': post.title,\n",
    "                         'body': post.selftext,\n",
    "                         'created': post.created}, ignore_index=True)\n",
    "        except:\n",
    "            # telling the loop to continue regardless of errors\n",
    "            next()\n",
    "\n",
    "    # telling the loop when to stop\n",
    "    if len(S) < 100:\n",
    "        break\n",
    "    # making sure posts pull from the next earliest date value\n",
    "    start_date = df['created'].max()\n",
    "    print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3hNChtDEJuY"
   },
   "outputs": [],
   "source": [
    "df['created'] = pd.to_datetime(df['created'],unit='s')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpXwtwlyERy6"
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"title\"] + df[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"title\", \"body\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# data pre processing from TextBlob\n",
    "def preprocess(text):\n",
    "    text = text.str.replace(\"(<br/>)\", \"\")\n",
    "    text = text.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    text = text.str.replace('(&amp)', '')\n",
    "    text = text.str.replace('(&gt)', '')\n",
    "    text = text.str.replace('(&lt)', '')\n",
    "    text = text.str.replace('(\\xa0)', ' ')  \n",
    "    return text\n",
    "df['text'] = preprocess(df['text'])\n",
    "\n",
    "df['polarity'] = df['text'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df['review_len'] = df['text'].astype(str).apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cewrp1PDv1s3"
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"review_len\", \"word_count\", \"text\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\poppa\\OneDrive - University of Bristol\\3rd\\data science\\project\\r_stocks_data\\current\\month_polarity\\compile\\nov3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources\n",
    "# TextBlob Docs\n",
    "# Pushift PRAW Docs\n",
    "# David Little: 4-Step Reddit vs. NY Stock Exchange Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHHwgDKyv9SK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zcMDiUIwKeW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auW_vjlMwGcP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yMyNhIawJlt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "long_loop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
